# CSET-Georgetown-Adversarial-Attack-ML-Research

This repo contains all things pertinent to a semester-long ML-security research project I did as a part of my internship at the Center for Security and Emerging Technology at Georgetown. The code for training the ML victim models and adversarial attack models were all written in .pynb files. My research reports can be found in the folder titled "Final Report." In this repo, the training datasets and python scripts I used can also be found. 

Below are a few screenshots from the final presentation with a brief overview of project scope.


![Screen Shot 2023-01-27 at 1 13 51 AM](https://user-images.githubusercontent.com/70988841/215029470-dfe989eb-e9d3-44a2-b816-0c60ca799ff7.png)
![Screen Shot 2023-01-27 at 1 18 41 AM](https://user-images.githubusercontent.com/70988841/215030162-51e4d055-b77c-4d7f-9663-2d12f63db48f.png)
![Screen Shot 2023-01-27 at 1 18 11 AM](https://user-images.githubusercontent.com/70988841/215030107-18b9cc4e-3e64-4b2d-a326-c4f3a6b59d2a.png)
![Screen Shot 2023-01-27 at 1 14 04 AM](https://user-images.githubusercontent.com/70988841/215029493-4c0f60e0-f17a-46ea-841b-b1b56d62c653.png)
![Screen Shot 2023-01-27 at 1 20 10 AM](https://user-images.githubusercontent.com/70988841/215030344-f41dbe12-9197-42fb-a39a-a97d845ee269.png)
![Screen Shot 2023-01-27 at 1 13 23 AM](https://user-images.githubusercontent.com/70988841/215029404-daf50365-31ce-468c-ba5e-f58d3fe6f4ac.png)
